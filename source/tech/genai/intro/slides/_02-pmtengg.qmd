
# Prompt Engineering {#pmpteng}

---

### Definition


**Google Definition:**
: Prompt engineering is the art of asking the right question to get the best output from an LLM.

---

### Why Prompting is Engineering?

- *Strategic Crafting:* Crafting effective prompts requires understanding how different inputs influence the model's outputs, requires strategic approach to elicit desired responses.

- *Optimization for Specific Tasks:* Prompts must often be optimized for specific tasks or outcomes, such as generating code, writing in a particular style, or providing precise answers to questions.

- *Iterative Testing and Refinement:* Finding the most effective prompt often involves iterative testing and refinement.

- *Adaptation to Model Variations:* Different LLMs or even different versions of the same model may respond differently to the same prompt, requiring adjustments and customizations.

- *Balancing Brevity and Specificity:* Effective prompts balance being concise enough for practical use while providing sufficient specificity to guide the model's output accurately.
- *Leveraging Known Patterns:* Experienced prompt engineers leverage known patterns and tricks that have been found to improve model responses, such as using certain phrasings or including specific instructions within the prompt.
- *Understanding of Model Capabilities and Limitations:* Prompt engineers need a deep understanding of what the model can and cannot do, which guides how they frame prompts to avoid common pitfalls or misunderstandings.

---

### Elements of Prompt

- A prompt contains any of the following elements:

  - **Instruction**: a specific task or instruction you want the model to perform
  - **Context**: external information or additional context that can steer the model to better responses
  - **Input Data**: the input or question that we are interested to find a response for
  - **Output Indicator**: the type or format of the output.

::: {.callout-tip title="Example Prompt" icon="false" }

::: {layout-ncol=2}

|
| Classify the text into neutral, negative, or positive 
| Text: I think the food was okay.
| Sentiment:
|

|
| **Instruction:**    Classify the text into neutral, negative, or positive
| **Input:**          I think the food was okay.
| **Context:** 
| **Output:**         Sentiment:

:::

:::

---

### Simple Tips for Better Prompting

(@) The more detailed, the better output

::: {.callout}
::: {layout-ncol=2}

| [*Poor*]{style="color:brown;"}
| Write code to calculate the Fibonacci sequence

| [*Better*]{style="color:green;"}
| Write a Python function to efficiently calculate the Fibonacci sequence. Comment the code to explain why it's written that way.
:::

:::

(@) Explicitly mention the persona to adopt by the model

::: {.callout}
::: {layout-row=2}

| [*Poor*]{style="color:brown;"}
| User Message: Suggest medicine to mild seasonal allergies

| [*Better*]{style="color:green;"}
| System Prompt: "You are a knowledgeable Medical Assistant. Provide advice on managing health concerns, emphasizing natural remedies and lifestyle changes where applicable. Ensure all suggestions are safe and generally recognized as effective by medical professionals. Remind users to consult a healthcare provider for personalized advice." 
| 
| User Message: "I've been struggling with mild seasonal allergies and I really prefer not to use over-the-counter medications. Are there any natural remedies or lifestyle adjustments I can try to alleviate my symptoms?"
:::
:::

---

### Contd.

(@) Use delimiters to clearly indicate different parts of the input

::: {.callout}
Summarize the text delimited by triple quotes.

"""A very lengthy text to summarize"""
:::
   
(@) Clearly mention the desired output

::: {.callout}
Summarize the text delimited by triple quotes in `5 bullet points`.

"""A very lengthy text to summarize"""
:::

(@) Add context information

::: {.callout}
Context: A car manufacturer is planning to introduce a new electric vehicle (EV) model targeted at young professionals who are environmentally conscious and prefer tech-savvy vehicles. The car is designed with advanced features such as autonomous driving capabilities, integrated smart home connectivity, and an AI assistant for vehicle diagnostics and personalized driving experiences. The company aims to position this model as a premium yet affordable option in the EV market.
Task: Write a press release announcing the launch of the new electric vehicle, highlighting its unique features, target audience, and how it sets a new standard in the eco-friendly automotive industry?

:::

---

### Prompt Techniques 

- #### Zero-shot Prompting
  - With single prompt instruction, getting the desired output
  - Also knows as Direct Prompting
  - Simplest prompt type 

::: {.callout}
| **Example**
|     Classify the text into neutral, negative, or positive
|     Text: I think the food was okay.
|     Sentiment:
:::

---

### Few-shot Prompting

- #### Few-shot Prompting
  - Also knows as Multi-Shot prompting
  - Need to provide one or more examples of what need to be done 
  - it enable in-context learning from the provided examples

::: {.callout}
| **Sentiment Analysis Example**
|   Crystal clear display, perfect for movies. // Positive
|    Battery life not as advertised. Disappointed. // Negative
|    Easy setup, great sound quality. Would recommend! // Positive
|    Confusing instructions, took forever to install. // Negative
|    Lightweight and sleek design. Love it! // Positive
|    It doesn't work! // 
:::

--- 

### Chain of Thoughts (CoT)

- #### Chain of Thoughts
  - enables complex reasoning capabilities through intermediate reasoning steps.
  - Combing with Few-Shot prompting gives better results

::: {.callout}
| **Example**
|   The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
|   A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.
|   The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.
|   A:
:::

--- 

### Other Techniques

- Prompt Chaining
- Tree of Thoughts
- Retrieval Augmented Generation (RAG)
- ReAct Prompting
- Multimodal CoT Prompting
- Graph Prompting

---

### Model Parameters

Key parameters influence the LLM output

**Temparature**
: controls the degree of randomness in the token selection

- Value ranges from 0 to 1
- 0 means the  highest probability tokens are selected
- 1 means the opposite
- Select low value for more fact based scenarios
- Select highest value for more creative content

**top_p**
: influence how the tokens are selected

- Tokens are selected from the most to least probable until the sum of their probabilities equals the top_p value
- value is range from 0 to 2
- for exact and factual outputs, low value is better

---

### Model Parameters contd.

**top_k**
: number of probable next words, to create a pool of words to choose from

<br/>

**stop sequence**
: sequence of characters to tell the model to stop generating content.

- on first encounter of these words model will stop generating the output.

<br/>

**max_tokens**
: specify the maximum number of tokens that can be generated in the response

---

[Back to Index](#index)